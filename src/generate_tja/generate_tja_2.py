import torch
import librosa
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer
from tqdm import tqdm
import os

# âœ… è®¾å¤‡æ£€æµ‹
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… åŠ è½½ LLaMA2-13B
MODEL_PATH = "model/llama2_13B_taiko"
model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, torch_dtype=torch.float16, device_map="auto").to(device)
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

# âœ… è®¾ç½® Pad Token
tokenizer.pad_token = tokenizer.eos_token

def extract_bpm(audio_path):
    """ ä½¿ç”¨ librosa è‡ªåŠ¨æ£€æµ‹ BPM """
    y, sr = librosa.load(audio_path, sr=22050)
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    return int(tempo) if tempo else 143  # é»˜è®¤ BPM 143

def clean_tja_output(output_text):
    """ è¿‡æ»¤ AI ç”Ÿæˆçš„æ— å…³å†…å®¹ï¼Œç¡®ä¿åªä¿ç•™ TJA æ ¼å¼æ•°æ® """
    lines = output_text.split("\n")
    clean_lines = []

    for line in lines:
        line = line.strip()

        if "Notes:" in line or "0: Empty beat" in line:
            continue  # è·³è¿‡ AI å¯èƒ½å†™çš„è¯´æ˜

        if line.startswith("Generate a Taiko no Tatsujin"):
            continue  # è·³è¿‡ prompt å¤è¿°

        clean_lines.append(line)

    return "\n".join(clean_lines)

def generate_tja(audio_path, output_dir="output", offset=0):
    """ ğŸµ ç”Ÿæˆå®Œæ•´çš„ TJA è°±é¢ """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    bpm = extract_bpm(audio_path)
    song_name = os.path.basename(audio_path).replace(".mp3", "").replace(".wav", "")
    tja_filename = os.path.join(output_dir, f"{song_name}.tja")

    difficulties = {"Easy": 3, "Normal": 5, "Hard": 7, "Oni": 9}
    tja_content = ""

    for course, level in tqdm(difficulties.items(), desc="ğŸµ ç”Ÿæˆè°±é¢ä¸­..."):
        print(f"ğŸµ ç”Ÿæˆ {course} ({level}) è°±é¢ä¸­...")

        prompt = f"""
Generate a Taiko no Tatsujin drum chart in TJA format.
Output ONLY the TJA data, do not explain anything.

TITLE: {song_name}
BPM: {bpm}
OFFSET: {offset}
WAVE: {song_name}.mp3

COURSE: {course}
LEVEL: {level}
#START
"""

        # âœ… å‘é€åˆ° LLM
        input_data = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=2048, padding="max_length").to(device)

        with torch.no_grad():
            output = model.generate(
                input_ids=input_data["input_ids"],
                attention_mask=input_data["attention_mask"],
                max_new_tokens=4000,  # âœ… å¢åŠ æœ€å¤§ Token é™åˆ¶
                temperature=0.7,
                do_sample=True,
                top_k=50,
                top_p=0.95,
                repetition_penalty=1.1,
                pad_token_id=tokenizer.pad_token_id
            )

        # âœ… è§£æ LLM ç”Ÿæˆçš„å†…å®¹
        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
        clean_text = clean_tja_output(generated_text)

        # âœ… ç¡®ä¿è°±é¢ä¸ä¸ºç©º
        if len(clean_text.strip()) == 0:
            print(f"âš ï¸ ç”Ÿæˆçš„ {course} è°±é¢ä¸ºç©ºï¼Œä½¿ç”¨å ä½ç¬¦")
            clean_text = "100000000,010000000,001000000,000100000,000010000,000001000,"

        # âœ… æ·»åŠ åˆ°æœ€ç»ˆ TJA
        tja_content += f"COURSE:{course}\nLEVEL:{level}\n#START\n{clean_text}\n#END\n\n"

    # âœ… ä¿å­˜ TJA æ–‡ä»¶
    with open(tja_filename, "w", encoding="utf-8") as f:
        f.write(tja_content)

    print(f"âœ… TJA è°±é¢å·²ç”Ÿæˆï¼š{tja_filename}")
    return tja_filename

# **æµ‹è¯•**
if __name__ == "__main__":
    audio_file = "audio/ReadyNow.mp3"
    generate_tja(audio_file)
